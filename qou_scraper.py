import requests
from bs4 import BeautifulSoup
import os
from typing import Optional, List, Dict, Any
from datetime import datetime
import logging
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet
import arabic_reshaper
from bidi.algorithm import get_display
from io import BytesIO
import cloudscraper
import time
import random
from urllib.parse import urljoin
import re

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("qou_bot.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('qou_scraper')

# URLs
BASE_URL = 'https://portal.qou.edu'
LOGIN_URL = 'https://portal.qou.edu/login.do'
INBOX_URL = 'https://portal.qou.edu/student/inbox.do'
TERM_SUMMARY_URL = 'https://portal.qou.edu/student/showTermSummary.do'
WEEKLY_MEETINGS_URL = 'https://portal.qou.edu/student/showTermSchedule.do'
BALANCE_URL = 'https://portal.qou.edu/student/getSasStudFtermCardList.do'
EXAMS_SCHEDULE_URL = 'https://portal.qou.edu/student/examsScheduleView.do'
GRADES_URL = 'https://portal.qou.edu/student/showTermSummary.do'

# User Agents rotating
USER_AGENTS = [
    "Mozilla/5.0 (Linux; Android 13; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Mobile Safari/537.36 Edg/140.0.0.0",
    "Mozilla/5.0 (Linux; Android 12; SM-S906N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Mobile Safari/537.36",
    "Mozilla/5.0 (Linux; Android 10; SM-G981B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Mobile Safari/537.36",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1"
]

class QOUScraper:
    def __init__(self, student_id: str, password: str):
        self.student_id = student_id
        self.password = password
        self.session = self._create_session()
        self.is_logged_in = False
        logger.info(f"Initialized scraper for student: {student_id}")

    def _create_session(self):
        """Ø¥Ù†Ø´Ø§Ø¡ session Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ù…Ø§ÙŠØ©"""
        scraper = cloudscraper.create_scraper(
            browser={
                'browser': 'chrome',
                'platform': 'android',
                'mobile': True,
                'desktop': False,
            },
            delay=10,
            interpreter='nodejs',
        )
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª session Ø¥Ø¶Ø§ÙÙŠØ©
        scraper.headers.update({
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "ar,en-US;q=0.7,en;q=0.3",
            "Accept-Encoding": "gzip, deflate, br",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "same-origin",
            "Sec-Fetch-User": "?1",
        })
        
        return scraper

    def _get_random_user_agent(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ user agent Ø¹Ø´ÙˆØ§Ø¦ÙŠ"""
        return random.choice(USER_AGENTS)

    def _simulate_human_delay(self):
        """Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªØ£Ø®ÙŠØ± Ø§Ù„Ø¨Ø´Ø±ÙŠ"""
        time.sleep(random.uniform(1, 3))

    def login(self) -> bool:
        """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù…Ø¨Ø³Ø· - Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙ‚Ø·"""
        try:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ù„Ø³Ø© Ø£ÙˆÙ„Ø§Ù‹
            self.session = self._create_session()
            self.is_logged_in = False
            
            time.sleep(random.uniform(2, 4))
            
            # 1. Ø¥Ø¹Ø¯Ø§Ø¯ headers ÙƒØ§Ù…Ù„Ø© ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø£ØµÙ„ÙŠ
            headers = {
                "User-Agent": self._get_random_user_agent(),
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
                "Accept-Encoding": "gzip, deflate, br, zstd",
                "Accept-Language": "ar,en;q=0.9,en-GB;q=0.8,en-US;q=0.7",
                "Cache-Control": "max-age=0",
                "Content-Type": "application/x-www-form-urlencoded",
                "Origin": "https://portal.qou.edu",
                "Referer": "https://portal.qou.edu/login.do",
                "Sec-Ch-Ua": '"Chromium";v="140", "Not=A?Brand";v="24", "Microsoft Edge";v="140"',
                "Sec-Ch-Ua-Mobile": "?1",
                "Sec-Ch-Ua-Platform": '"Android"',
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "same-origin",
                "Sec-Fetch-User": "?1",
                "Upgrade-Insecure-Requests": "1",
                "Priority": "u=0, i"
            }
            
            # 2. Ø¥Ø¹Ø¯Ø§Ø¯ payload Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø© Ø£ÙˆÙ„Ø§Ù‹
            payload = {
                "uip": "172.68.234.77",  # Ù‚ÙŠÙ…Ø© Ø«Ø§Ø¨ØªØ© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                "defaultUserSettingMode": "light",  # Ù‚ÙŠÙ…Ø© Ø«Ø§Ø¨ØªØ©
                "userId": self.student_id,
                "password": self.password,
                "logBtn": "Ø¯Ø®ÙˆÙ„"
            }
            
            # 3. Ø¥Ø¶Ø§ÙØ© cookies Ø£Ø³Ø§Ø³ÙŠØ© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            self.session.cookies.update({
                "_ga": "GA1.1.1230287084.1753970669",
                "_gid": "GA1.2.1283861126.1757582758",
            })
            
            # 4. Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Login Ù…Ø¨Ø§Ø´Ø±Ø©
            logger.info(f"Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„Ù€ {self.student_id}")
            login_resp = self.session.post(
                LOGIN_URL,
                data=payload,
                headers=headers,
                timeout=30,
                allow_redirects=True
            )
            
            # 5. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Ø¬Ø§Ø­
            if self._check_login_success(login_resp.text):
                logger.info(f"âœ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù†Ø§Ø¬Ø­ Ù„Ù€ {self.student_id}")
                self.is_logged_in = True
                return True
            else:
                logger.warning(f"âŒ ÙØ´Ù„ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù€ {self.student_id}")
                # ØªØ­Ù„ÙŠÙ„ Ø³Ø¨Ø¨ Ø§Ù„ÙØ´Ù„
                if "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ùˆ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±" in login_resp.text:
                    logger.error("Ø³Ø¨Ø¨ Ø§Ù„ÙØ´Ù„: Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ø®ÙˆÙ„ ØºÙŠØ± ØµØ­ÙŠØ­Ø©")
                elif "error" in login_resp.text.lower():
                    logger.error("Ø³Ø¨Ø¨ Ø§Ù„ÙØ´Ù„: Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…")
                return False
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„Ù€ {self.student_id}: {str(e)}")
            return False

    def _check_login_success(self, html_content: str) -> bool:
        """ØªØ­Ù‚Ù‚ Ø¯Ù‚ÙŠÙ‚ Ù…Ù† Ù†Ø¬Ø§Ø­ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„"""
        # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù†Ø¬Ø§Ø­
        success_indicators = [
            "studentPortal", "portalHome", "student/home",
            "Ù…Ø±Ø­Ø¨Ø§", "Ø£Ù‡Ù„Ø§Ù‹", "Ø·Ø§Ù„Ø¨", "Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", 
            "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬", "logout", "log out",
            "Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ", "Ø§Ù„Ø¯Ø±Ø¬Ø§Øª", "Ø§Ù„Ø±ØµÙŠØ¯", "inbox"
        ]
        
        # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙØ´Ù„
        error_indicators = [
            "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ùˆ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±",
            "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", "ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ± Ø®Ø§Ø·Ø¦Ø©",
            "Ø§Ø³Ù… Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± ØµØ­ÙŠØ­", "invalid", "error",
            "ÙØ´Ù„", "failed", "ØºÙŠØ± Ù…ØµØ±Ø­"
        ]
        
        content_lower = html_content.lower()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø®Ø·Ø£ Ø£ÙˆÙ„Ø§Ù‹
        for error in error_indicators:
            if error.lower() in content_lower:
                logger.warning(f"ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„: {error}")
                return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù†Ø¬Ø§Ø­
        for success in success_indicators:
            if success.lower() in content_lower:
                return True
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù†Ø§ØµØ± ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø·Ø§Ù„Ø¨
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø·Ø§Ù„Ø¨
        student_menus = soup.find_all(['a', 'div'], string=lambda text: text and any(
            x in (text.lower() if text else '') for x in ['Ø§Ù„Ø¬Ø¯ÙˆÙ„', 'Ø§Ù„Ø¯Ø±Ø¬Ø§Øª', 'Ø§Ù„Ø±ØµÙŠØ¯', 'Ø§Ù„Ø±Ø³Ø§Ø¦Ù„', 'inbox', 'grades']
        ))
        
        if student_menus:
            return True
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ù„Ø·Ø§Ù„Ø¨
        student_links = soup.find_all('a', href=lambda href: href and any(
            x in (href.lower() if href else '') for x in ['/student/', 'inbox', 'grades', 'schedule']
        ))
        
        if student_links:
            return True
        
        return False

    def ensure_login(self):
        """Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø³Ø¬Ù„ Ø§Ù„Ø¯Ø®ÙˆÙ„"""
        if not self.is_logged_in:
            success = self.login()
            if not success:
                logger.error(f"Failed to login for student: {self.student_id}")
            return success
        return True

    def fetch_student_info(self) -> Optional[Dict[str, str]]:
        """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
        if not self.ensure_login():
            return None
            
        try:
            self._simulate_human_delay()
            resp = self.session.get(BASE_URL, timeout=30)
            resp.raise_for_status()
            
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ ÙÙŠ Ø§Ù„ØµÙØ­Ø©
            student_info = {}
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø§Ù„Ø·Ø§Ù„Ø¨
            name_element = (soup.find('span', class_='student-name') or 
                          soup.find('div', class_='user-info') or
                          soup.find('span', string=lambda text: text and 'Ù…Ø±Ø­Ø¨Ø§' in text))
            
            if name_element:
                student_info['name'] = name_element.get_text(strip=True)
            
            return student_info if student_info else None
            
        except Exception as e:
            logger.error(f"Error fetching student info for {self.student_id}: {str(e)}")
            return None

    def fetch_latest_message(self) -> Optional[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ø¢Ø®Ø± Ø±Ø³Ø§Ù„Ø©"""
        if not self.ensure_login():
            return None
            
        try:
            self._simulate_human_delay()
            resp = self.session.get(INBOX_URL, timeout=30)
            resp.raise_for_status()
            
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¨Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©
            table = (soup.find('table', id='dataTable') or 
                   soup.find('table', class_='table') or
                   soup.find('table'))
            
            if not table:
                return None

            rows = table.find_all('tr')
            if len(rows) < 2:  # Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„ + ØµÙ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
                return None

            # Ø£Ø®Ø° Ø£ÙˆÙ„ ØµÙ Ø¨Ø¹Ø¯ Ø§Ù„Ø±Ø£Ø³
            first_row = rows[1]
            cols = first_row.find_all('td')
            
            if len(cols) < 5:
                return None

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            link_tag = cols[3].find('a') if len(cols) > 3 else None
            if not link_tag or not link_tag.get('href'):
                return None

            msg_id = link_tag['href'].split('msgId=')[-1] if 'msgId=' in link_tag['href'] else 'unknown'
            full_link = urljoin(INBOX_URL, link_tag['href'])
            
            subject = link_tag.get_text(strip=True)
            sender = cols[6].get_text(strip=True) if len(cols) > 6 else ''
            date = cols[4].get_text(strip=True) if len(cols) > 4 else ''

            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
            msg_resp = self.session.get(full_link, timeout=30)
            msg_resp.raise_for_status()
            soup_msg = BeautifulSoup(msg_resp.text, 'html.parser')

            body = (soup_msg.find('div', class_='message-body') or 
                   soup_msg.find('div', id='messageContent') or
                   soup_msg.find('body'))
            body_text = body.get_text(strip=True) if body else ''

            return {
                'msg_id': msg_id,
                'subject': subject,
                'sender': sender,
                'date': date,
                'body': body_text
            }
            
        except Exception as e:
            logger.error(f"Error fetching message for {self.student_id}: {str(e)}")
            return None

    def validate_credentials(self) -> Dict[str, Any]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯"""
        result = {
            "valid": False,
            "message": "âŒ ÙØ´Ù„ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.",
            "details": {}
        }
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙ†Ø³ÙŠÙ‚ Ø±Ù‚Ù… Ø§Ù„Ø·Ø§Ù„Ø¨
        if not self.student_id.isdigit() or len(self.student_id) != 13:
            result["message"] = "âŒ Ø±Ù‚Ù… Ø§Ù„Ø·Ø§Ù„Ø¨ ØºÙŠØ± ØµØ­ÙŠØ­ (ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† 13 Ø±Ù‚Ù…Ù‹Ø§)"
            return result
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
        if not self.password or len(self.password) < 6:
            result["message"] = "âŒ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©"
            return result
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        if self.login():
            result["valid"] = True
            result["message"] = "âœ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù†Ø§Ø¬Ø­"
            # Ø¬Ù„Ø¨ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„Ù„ØªØ£ÙƒØ¯
            student_info = self.fetch_student_info()
            if student_info:
                result["details"] = student_info
        else:
            result["message"] = "âŒ ÙØ´Ù„ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
        
        return result

    def fetch_term_summary_courses(self) -> List[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØµÙ„"""
        if not self.ensure_login():
            return []
            
        try:
            self._simulate_human_delay()
            resp = self.session.get(TERM_SUMMARY_URL, timeout=30)
            resp.raise_for_status()
            
            soup = BeautifulSoup(resp.text, 'html.parser')
            courses = []
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¨Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©
            table = (soup.find('table', id='dataTable') or 
                   soup.find('table', class_='table') or
                   soup.find('table'))
            
            if not table:
                return courses

            rows = table.find_all('tr')[1:]  # ØªØ®Ø·ÙŠ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„
            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 7:
                    continue

                course = {
                    'course_code': cols[0].get_text(strip=True),
                    'course_name': cols[1].get_text(strip=True),
                    'credit_hours': cols[2].get_text(strip=True),
                    'status': cols[3].get_text(strip=True),
                    'midterm_mark': cols[4].get_text(strip=True) or "-",
                    'final_mark': cols[5].get_text(strip=True) or "-",
                    'final_mark_date': cols[6].get_text(strip=True) or "-"
                }
                courses.append(course)
                
            return courses
            
        except Exception as e:
            logger.error(f"Error fetching courses for {self.student_id}: {str(e)}")
            return []

def fetch_balance_totals(self) -> Dict[str, Any]:
    """Ø¬Ù„Ø¨ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±ØµÙŠØ¯"""
    if not self.ensure_login():
        return {"error": "Ù„Ù… ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„"}
        
    try:
        self._simulate_human_delay()
        resp = self.session.get(BALANCE_URL, timeout=30)
        resp.raise_for_status()
        
        soup = BeautifulSoup(resp.text, 'html.parser')
        rows = soup.select("table#dataTable tbody tr")
        
        if not rows:
            return {"error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±ØµÙŠØ¯"}

        total_required = total_paid = total_grants = total_balance = 0.0

        for row in rows:
            cols = [c.get_text(strip=True).replace(',', '') for c in row.find_all("td")]
            if len(cols) < 7:
                continue
            try:
                total_required += float(cols[1])
                total_paid     += float(cols[2])
                total_grants   += float(cols[4])
                total_balance  += float(cols[5])
            except ValueError:
                continue

        return {
            "total_required": total_required,
            "total_paid": total_paid,
            "total_grants": total_grants,
            "total_balance": total_balance,
            "formatted_text": f"ğŸ“Œ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„ÙŠ Ù„Ù„Ø±ØµÙŠØ¯:\n\nğŸ’° Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {total_required:,.2f}\nâœ… Ø§Ù„Ù…Ø¯ÙÙˆØ¹: {total_paid:,.2f}\nğŸ“ Ø§Ù„Ù…Ù†Ø­: {total_grants:,.2f}\nğŸ“Š Ø±ØµÙŠØ¯ Ø§Ù„ÙØµÙ„: {total_balance:,.2f}"
        }
        
    except Exception as e:
        logger.error(f"Error fetching balance for {self.student_id}: {str(e)}")
        return {"error": "âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±ØµÙŠØ¯"}
            
    
