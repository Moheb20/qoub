import requests
from bs4 import BeautifulSoup
import os
from typing import Optional, List
from datetime import datetime
import logging
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet
import arabic_reshaper
from bidi.algorithm import get_display
from io import BytesIO
import database 
from typing import Dict, Any

font_path = os.path.join(os.path.dirname(__file__), 'fonts', 'arial.ttf')
pdfmetrics.registerFont(TTFont('Arial', font_path))
STUDY_PLAN_URL = "https://portal.qou.edu/student/showMajorSheet.do" 
LOGIN_URL = 'https://portal.qou.edu/login.do'
INBOX_URL = 'https://portal.qou.edu/student/inbox.do'
TERM_SUMMARY_URL = 'https://portal.qou.edu/student/showTermSummary.do'
WEEKLY_MEETINGS_URL = 'https://portal.qou.edu/student/showTermSchedule.do'
BALANCE_URL = 'https://portal.qou.edu/student/getSasStudFtermCardList.do'
EXAMS_SCHEDULE_URL = 'https://portal.qou.edu/student/examsScheduleView.do'
cel = 'https://portal.qou.edu/calendarProposed.do'
logger = logging.getLogger(__name__)
EXAM_TYPE_MAP = {
    "MT&IM": "ğŸ“ Ø§Ù„Ù†ØµÙÙŠ",
    "FT&IF": "ğŸ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù†Ø¸Ø±ÙŠ",
    "FP&FP": "ğŸ§ª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ø¹Ù…Ù„ÙŠ",
    "LE&LE": "ğŸ“ˆ Ø§Ù…ØªØ­Ø§Ù† Ø§Ù„Ù…Ø³ØªÙˆÙ‰",
}

class QOUScraper:
    def __init__(self, student_id: str, password: str):
        self.session = requests.Session()
        self.student_id = student_id
        self.password = password

    def login(self) -> bool:
        self.session.get(LOGIN_URL)
        params = {
            'userId': self.student_id,
            'password': self.password,
            'logBtn': 'Login'
        }
        resp = self.session.post(LOGIN_URL, data=params, allow_redirects=True)
        return 'student' in resp.url

    def fetch_latest_message(self) -> Optional[dict]:
        resp = self.session.get(INBOX_URL)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, 'html.parser')

        row = soup.select_one("tbody tr")
        if not row:
            return None

        link_tag = row.select_one("td[col_4] a[href*='msgId=']")
        if not link_tag:
            return None

        msg_id = link_tag['href'].split('msgId=')[-1]
        full_link = requests.compat.urljoin(INBOX_URL, link_tag['href'])
        subject = link_tag.get_text(strip=True)

        sender = row.select_one("td[col_7]")
        sender_text = sender.get_text(strip=True) if sender else ''

        date = row.select_one("td[col_5]")
        date_text = date.get_text(strip=True) if date else ''

        resp_msg = self.session.get(full_link)
        resp_msg.raise_for_status()
        soup_msg = BeautifulSoup(resp_msg.text, 'html.parser')

        body = soup_msg.find('div', class_='message-body')
        body_text = body.get_text(strip=True) if body else ''

        return {
            'msg_id': msg_id,
            'subject': subject,
            'sender': sender_text,
            'date': date_text,
            'body': body_text
        }

    def fetch_term_summary_courses(self) -> List[dict]:
        resp = self.session.get(TERM_SUMMARY_URL)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, 'html.parser')

        courses = []
        table = soup.find('table', id='dataTable')
        if not table:
            return courses

        rows = table.find('tbody').find_all('tr')
        for row in rows:
            cols = row.find_all('td')
            if len(cols) < 7:
                continue

            course = {
                'course_code': cols[0].get_text(strip=True),
                'course_name': cols[1].get_text(strip=True),
                'credit_hours': cols[2].get_text(strip=True),
                'status': cols[3].get_text(strip=True),
                'midterm_mark': cols[4].get_text(strip=True) or "-",
                'final_mark': cols[5].get_text(strip=True) or "-",
                'final_mark_date': cols[6].get_text(strip=True) or "-"
            }
            courses.append(course)
        return courses

    def fetch_lectures_schedule(self) -> List[dict]:
        resp = self.session.get(WEEKLY_MEETINGS_URL)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, 'html.parser')

        meetings = []
        table = soup.find('table', class_='table table-hover table-condensed table-striped table-curved')
        if not table:
            return meetings

        rows = table.find('tbody').find_all('tr')
        for row in rows:
            cols = row.find_all('td')
            if len(cols) < 12:
                continue

            meeting = {
                'course_code': cols[0].get_text(strip=True),
                'course_name': cols[1].get_text(strip=True),
                'credit_hours': cols[2].get_text(strip=True),
                'section': cols[3].get_text(strip=True),
                'day': cols[4].get_text(strip=True),
                'time': cols[5].get_text(strip=True),
                'building': cols[6].get_text(strip=True),
                'room': cols[7].get_text(strip=True),
                'lecturer': cols[8].get_text(strip=True),
                'office_hours': cols[9].get_text(strip=True),
                'course_content_link': cols[10].find('a')['href'] if cols[10].find('a') else '',
                'study_plan_link': cols[11].find('a')['href'] if cols[11].find('a') else ''
            }
            meetings.append(meeting)

        return meetings

    def fetch_term_summary_stats(self) -> dict:
        resp = self.session.get(TERM_SUMMARY_URL)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, 'html.parser')

        stats_table = soup.find('table', id='dataTable3')
        if not stats_table:
            return {}

        rows = stats_table.find('tbody').find_all('tr')
        if len(rows) < 2:
            return {}

        def parse_row(row):
            cols = row.find_all('td')
            return {
                'type': cols[0].get_text(strip=True),
                'registered_hours': cols[1].get_text(strip=True),
                'passed_hours': cols[2].get_text(strip=True),
                'counted_hours': cols[3].get_text(strip=True),
                'failed_hours': cols[4].get_text(strip=True),
                'withdrawn_hours': cols[5].get_text(strip=True),
                'points': cols[6].get_text(strip=True),
                'gpa': cols[7].get_text(strip=True),
                'honor_list': cols[8].get_text(strip=True)
            }

        return {
            'term': parse_row(rows[0]),
            'cumulative': parse_row(rows[1])
        }

    def parse_exam_datetime(self, date_str, time_str):
        """ÙŠØ­ÙˆÙ‘Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® + Ø§Ù„ÙˆÙ‚Øª Ù…Ù† Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ datetime Ø¬Ø§Ù‡Ø²"""
        try:
            # Ø¯Ø¹Ù… 23-08-2025 Ø¨Ø¯Ù„ 23/08/2025
            dt = datetime.strptime(f"{date_str} {time_str}", "%d-%m-%Y %H:%M")
            return dt.replace(tzinfo=PALESTINE_TZ)
        except Exception:
            return None
    # ------------------- Ø¬Ù„Ø¨ Ø¢Ø®Ø± ÙØµÙ„ÙŠÙ† -------------------
    def get_last_two_terms(self):
        resp = self.session.get(EXAMS_SCHEDULE_URL)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        select_term = soup.find("select", {"name": "termNo"})
        if not select_term:
            return []
        options = select_term.find_all("option")
        # Ø¹Ø§Ø¯Ø©Ù‹ ÙŠÙƒÙˆÙ† Ø£ÙˆÙ„ Ø®ÙŠØ§Ø± Ù‡Ùˆ Ø§Ù„ÙØµÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠØŒ Ø§Ù„Ø«Ø§Ù†ÙŠ Ø§Ù„Ø³Ø§Ø¨Ù‚
        last_two = options[:2]
        return [{'value': opt['value'], 'label': opt.get_text(strip=True)} for opt in last_two]

    # ------------------- Ø¬Ù„Ø¨ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø§Ù…ØªØ­Ø§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø¨ÙˆØ§Ø¨Ø© -------------------
    def fetch_exam_schedule(self, term_no, exam_type) -> List[dict]:
        payload = {
            "termNo": term_no,
            "examType": exam_type
        }

        resp = self.session.post(EXAMS_SCHEDULE_URL, data=payload)
        resp.raise_for_status()

        soup = BeautifulSoup(resp.text, "html.parser")
        table = soup.find("table", id="dataTable")
        if not table:
            return []

        exams = []
        rows = table.find("tbody").find_all("tr")
        for row in rows:
            cols = row.find_all("td")
            if len(cols) < 11:
                continue

            exam = {
                "exam_kind": cols[0].get_text(strip=True),
                "course_code": cols[1].get_text(strip=True),
                "course_name": cols[2].get_text(strip=True),
                "lecturer": cols[3].get_text(strip=True),
                "section": cols[4].get_text(strip=True),
                "day": cols[5].get_text(strip=True),
                "date": cols[6].get_text(strip=True),
                "session": cols[7].get_text(strip=True),
                "from_time": cols[8].get_text(strip=True),
                "to_time": cols[9].get_text(strip=True),
                "note": cols[10].get_text(strip=True)
            }
            exams.append(exam)

        return exams
        
    def fetch_gpa(self):
        stats = self.fetch_term_summary_stats()
        if not stats:
            return None
        
        return {
            "term_gpa": stats['term']['gpa'] if stats['term'].get('gpa') else "ØºÙŠØ± Ù…ØªÙˆÙØ±",
            "cumulative_gpa": stats['cumulative']['gpa'] if stats['cumulative'].get('gpa') else "ØºÙŠØ± Ù…ØªÙˆÙØ±"
        }

    
        return {
            "term_gpa": stats.get('term', {}).get('gpa', 'ØºÙŠØ± Ù…ØªÙˆÙØ±'),
            "cumulative_gpa": stats.get('cumulative', {}).get('gpa', 'ØºÙŠØ± Ù…ØªÙˆÙØ±'),

            "term_gpa": clean(stats.get('term', {}).get('gpa')),
            "cumulative_gpa": clean(stats.get('cumulative', {}).get('gpa'))
        }


    def fetch_discussion_sessions(self) -> List[dict]:
        resp = self.session.get(WEEKLY_MEETINGS_URL)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, 'html.parser')

        sessions = []
        table = soup.find("table", {"id": "dataTable"})
        if not table:
            return sessions

        rows = table.find("tbody").find_all("tr")
        for row in rows:
            cols = row.find_all("td")
            if len(cols) < 5:
                continue
            session = {
                "course_code": cols[0].get_text(strip=True),
                "course_name": cols[1].get_text(strip=True),
                "section": cols[2].get_text(strip=True),
                "date": cols[3].get_text(strip=True),  # 17/08/2025
                "time": cols[4].get_text(strip=True)   # 11:00 - 12:00
            }
            sessions.append(session)
        return sessions
    def fetch_balance_table_pdf(self) -> BytesIO:
        resp = self.session.get(BALANCE_URL)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, 'html.parser')

        rows = soup.select("table#dataTable tbody tr")
        if not rows:
            return None

        # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        columns = ["Ø§Ù„ÙØµÙ„", " Ø§Ù„Ù…Ø·Ù„ÙˆØ¨", " Ø§Ù„Ù…Ø¯ÙÙˆØ¹", " Ø§Ù„Ù…Ù†Ø­", "Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ"]
        data = [columns]

        for row in rows:
            cols = [c.get_text(strip=True).replace(',', '') for c in row.find_all("td")]
            if len(cols) < 7:
                continue
            data.append([cols[0], cols[1], cols[2], cols[4], cols[5]])

        if len(data) == 1:
            return None

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„ÙƒÙ„ Ø®Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„
        for i in range(1, len(data)):
            for j in range(len(data[i])):
                data[i][j] = get_display(arabic_reshaper.reshape(data[i][j]))

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        data[0] = [get_display(arabic_reshaper.reshape(col)) for col in data[0]]

        output = BytesIO()
        pdf = SimpleDocTemplate(output, pagesize=A4)
        elements = []

        style_sheet = getSampleStyleSheet()
        arabic_style = style_sheet['Normal']
        arabic_style.fontName = 'Arial'
        arabic_style.fontSize = 12

        # Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØµÙØ­Ø©
        title_text = get_display(arabic_reshaper.reshape("Ø±ØµÙŠØ¯ Ø§Ù„Ø·Ø§Ù„Ø¨"))
        elements.append(Paragraph(title_text, arabic_style))
        elements.append(Spacer(1, 12))

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„
        table = Table(data, repeatRows=1, hAlign='CENTER')
        style = TableStyle([
            ('FONTNAME', (0,0), (-1,-1), 'Arial'),
            ('BACKGROUND', (0,0), (-1,0), colors.lightblue),
            ('TEXTCOLOR', (0,0), (-1,0), colors.black),
            ('ALIGN', (0,0), (-1,-1), 'CENTER'),
            ('GRID', (0,0), (-1,-1), 0.5, colors.grey),
            ('BACKGROUND', (0,1), (-1,-1), colors.whitesmoke),
        ])
        table.setStyle(style)

        # ØªÙ„ÙˆÙŠÙ† Ø§Ù„ØµÙÙˆÙ Ø¨Ø§Ù„ØªÙ†Ø§ÙˆØ¨
        for i in range(1, len(data)):
            if i % 2 == 0:
                table.setStyle(TableStyle([('BACKGROUND', (0,i), (-1,i), colors.lightgrey)]))

        elements.append(table)
        pdf.build(elements)
        output.seek(0)
        return output

    def fetch_balance_totals(self) -> str:
        """
        ÙŠØ­Ø³Ø¨ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆÙŠØ¹Ø±Ø¶Ù‡ Ø¨Ø´ÙƒÙ„ Ù…Ø±ØªØ¨ Ø¹Ù„Ù‰ Telegram
        """
        resp = self.session.get(BALANCE_URL)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, 'html.parser')

        rows = soup.select("table#dataTable tbody tr")
        if not rows:
            return "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±ØµÙŠØ¯"

        total_required = total_paid = total_grants = total_balance = 0.0

        for row in rows:
            cols = [c.get_text(strip=True).replace(',', '') for c in row.find_all("td")]
            if len(cols) < 7:
                continue
            total_required += float(cols[1])
            total_paid     += float(cols[2])
            total_grants   += float(cols[4])
            total_balance  += float(cols[5])

        text = "ğŸ“Œ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„ÙŠ Ù„Ù„Ø±ØµÙŠØ¯:\n\n"
        text += f"ğŸ’° Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {total_required}\n"
        text += f"âœ… Ø§Ù„Ù…Ø¯ÙÙˆØ¹: {total_paid}\n"
        text += f"ğŸ“ Ø§Ù„Ù…Ù†Ø­: {total_grants}\n"
        text += f"ğŸ“Š Ø±ØµÙŠØ¯ Ø§Ù„ÙØµÙ„: {total_balance}\n"

        return text


    @staticmethod
    def get_active_calendar():
        res = requests.get(cel)
        res.encoding = "utf-8"
        soup = BeautifulSoup(res.text, "html.parser")
    
        # ÙƒÙ„ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù„ÙŠ Ù…Ø´ text-not-active
        active_rows = soup.find_all("tr", class_=lambda x: x != "text-not-active")
    
        if not active_rows:  # Ø¥Ø°Ø§ Ù…Ø§ ÙÙŠ Ø£ÙŠ ØµÙ
            return "Ù…Ø§ Ù„Ù‚ÙŠØª Ø£Ø­Ø¯Ø§Ø« Ø­Ø§Ù„ÙŠØ§Ù‹ ğŸ¤·â€â™‚ï¸"
    
        events = []
        for row in active_rows:
            cols = row.find_all("td")
            if len(cols) < 5:
                continue
            subject = cols[0].get_text(strip=True)
            week = cols[1].get_text(strip=True)
            day = cols[2].get_text(strip=True)
            start = cols[3].get_text(strip=True)
            end = cols[4].get_text(strip=True)
    
            event_text = f"""ğŸ—“ {subject}
    ğŸ“… {day} {week}
    â³ {start} â†’ {end}"""
            events.append(event_text)
    
        if not events:
            return "Ù…Ø§ Ù„Ù‚ÙŠØª Ø£Ø­Ø¯Ø§Ø« Ø­Ø§Ù„ÙŠØ§Ù‹ ğŸ¤·â€â™‚ï¸"
    
        return events[0]  # Ø£ÙˆÙ„ Ø­Ø¯Ø« ÙØ¹Ø§Ù„
    
    def get_current_week_type():
        start_date = datetime.strptime("13/09/2025", "%d/%m/%Y")
        today = datetime.today()
        
        delta_days = (today - start_date).days
        if delta_days < 0:
            return "ğŸ“… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠ: Ù„Ù… ÙŠØ¨Ø¯Ø£ Ø¨Ø¹Ø¯"
    
        week_number = delta_days // 7
        if week_number % 2 == 0:
            return "ğŸ“… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠ: ÙØ±Ø¯ÙŠ"
        else:
            return "ğŸ“… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠ: Ø²ÙˆØ¬ÙŠ"

    @staticmethod
    def get_full_current_semester_calendar():
        try:
            res = requests.get(cel, timeout=10)
            res.raise_for_status()
            res.encoding = "utf-8"
            soup = BeautifulSoup(res.text, "html.parser")
        
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØµÙˆÙ„
            semesters = soup.find_all("div", class_="text-warning")
            if not semesters:
                return "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ÙØµÙˆÙ„."
        
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØµÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø­Ø§Ù„ÙŠ (ØªØ­Ø³ÙŠÙ†)
            current_date = datetime.now()
            current_semester_div = None
            
            for semester_div in semesters:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÙŠØ® Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ÙØµÙ„ Ù…Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠ
                table = semester_div.find_next_sibling("table")
                if not table:
                    continue
                    
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØ§Ø±ÙŠØ® Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ÙØµÙ„ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                start_date_found = False
                for row in table.find_all("tr"):
                    cols = row.find_all("td")
                    if len(cols) >= 5:
                        date_text = cols[3].get_text(strip=True)
                        if date_text and date_text != "Ù…Ù† :":
                            try:
                                event_date = datetime.strptime(date_text, "%d/%m/%Y")
                                if event_date <= current_date:
                                    start_date_found = True
                                    break
                            except ValueError:
                                continue
                
                if start_date_found:
                    current_semester_div = semester_div
                    break
            
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ ÙØµÙ„Ù‹Ø§ Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ØŒ Ù†Ø£Ø®Ø° Ø¢Ø®Ø± ÙØµÙ„
            if not current_semester_div:
                current_semester_div = semesters[-1]
        
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ù„ÙØµÙ„
            table = current_semester_div.find_next_sibling("table")
            if not table:
                return "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„Ù„ÙØµÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ."
        
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù…Ø¹ ØªØµÙÙŠØ© Ø§Ù„ØµÙÙˆÙ ØºÙŠØ± Ø§Ù„Ù†Ø´Ø·Ø©
            events = []
            rows = table.find_all("tr")
            
            for row in rows:
                # ØªØ®Ø·ÙŠ Ø§Ù„ØµÙÙˆÙ ØºÙŠØ± Ø§Ù„Ù†Ø´Ø·Ø© (Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ©)
                if "text-not-active" in row.get("class", []):
                    continue
                    
                cols = row.find_all("td")
                if len(cols) < 5:
                    continue
                    
                subject = cols[0].get_text(strip=True).replace("Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ : ", "")
                week = cols[1].get_text(strip=True).replace("Ø§Ù„Ø§Ø³Ø¨ÙˆØ¹ : ", "")
                day = cols[2].get_text(strip=True).replace("Ø§Ù„ÙŠÙˆÙ… : ", "")
                start = cols[3].get_text(strip=True).replace("Ù…Ù† : ", "")
                end = cols[4].get_text(strip=True).replace("Ø§Ù„Ù‰ : ", "")
    
                event_text = f"""ğŸ—“ {subject}
    ğŸ“… {day} {week}
    â³ {start} â†’ {end}"""
                events.append(event_text)
        
            if not events:
                return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£Ø­Ø¯Ø§Ø« Ù„Ù„ÙØµÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ ğŸ¤·â€â™‚ï¸"
        
            # Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙØµÙ„
            semester_title = current_semester_div.get_text(strip=True)
            result = f"ğŸ“š {semester_title}\n\n" + "\n\n".join(events)
            
            return result
            
        except requests.RequestException:
            return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§."
        except Exception as e:
            return f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}"








    def fetch_study_plan(self) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø·Ø§Ù„Ø¨"""
        try:
            response = self.session.get(STUDY_PLAN_URL, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙØ­Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            if "Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©" not in response.text:
                logger.warning(f"Study plan page might be invalid for {self.student_id}")
                return {
                    'stats': {},
                    'courses': [],
                    'last_updated': datetime.now().isoformat(),
                    'status': 'error',
                    'error': 'Invalid study plan page'
                }
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
            stats = self._extract_study_stats(soup)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª
            courses = self._extract_courses(soup)
            
            return {
                'stats': stats,
                'courses': courses,
                'last_updated': datetime.now().isoformat(),
                'status': 'success'
            }
            
        except requests.exceptions.Timeout:
            logger.error(f"Timeout while fetching study plan for {self.student_id}")
            return {
                'stats': {},
                'courses': [],
                'last_updated': datetime.now().isoformat(),
                'status': 'error',
                'error': 'Request timeout'
            }
        except Exception as e:
            logger.error(f"Error fetching study plan for {self.student_id}: {e}")
            return {
                'stats': {},
                'courses': [],
                'last_updated': datetime.now().isoformat(),
                'status': 'error',
                'error': str(e)
            }
    
    def _extract_study_stats(self, soup) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© Ù…Ù† Ø§Ù„ØµÙØ­Ø©"""
        stats = {
            'total_hours_required': 0,
            'total_hours_completed': 0,
            'total_hours_transferred': 0,
            'semesters_count': 0,
            'plan_completed': False,
            'completion_percentage': 0
        }
        
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙÙŠ Ø§Ù„Ù‡ÙŠÙƒÙ„
            stats_table = soup.find('table', class_='table')
            if not stats_table:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø© Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                stats_elements = soup.select('.form-group .control-label, .form-group .col-sm-2')
                if stats_elements:
                    for i in range(0, len(stats_elements), 2):
                        if i+1 < len(stats_elements):
                            label = stats_elements[i].get_text(strip=True)
                            value = stats_elements[i+1].get_text(strip=True)
                            
                            if 'Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©' in label:
                                stats['total_hours_required'] = self._parse_number(value)
                            elif 'Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø¬ØªØ§Ø²Ø©' in label:
                                stats['total_hours_completed'] = self._parse_number(value)
                            elif 'Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø­ØªØ³Ø¨Ø©' in label:
                                stats['total_hours_transferred'] = self._parse_number(value)
                            elif 'Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„' in label:
                                stats['semesters_count'] = self._parse_number(value)
                            elif 'Ø§Ù†Ù‡Ù‰ Ø§Ù„Ø®Ø·Ø©' in label:
                                stats['plan_completed'] = 'Ù†Ø¹Ù…' in value or 'yes' in value.lower()
                return stats
            
            # Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø§Ù„Ø¬Ø¯ÙˆÙ„ØŒ Ù†Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†Ù‡
            rows = stats_table.find_all('tr')
            for row in rows:
                cols = row.find_all('td')
                if len(cols) == 2:
                    label = cols[0].get_text(strip=True)
                    value = cols[1].get_text(strip=True)
                    
                    if 'Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©' in label:
                        stats['total_hours_required'] = self._parse_number(value)
                    elif 'Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø¬ØªØ§Ø²Ø©' in label:
                        stats['total_hours_completed'] = self._parse_number(value)
                    elif 'Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø­ØªØ³Ø¨Ø©' in label:
                        stats['total_hours_transferred'] = self._parse_number(value)
                    elif 'Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„' in label:
                        stats['semesters_count'] = self._parse_number(value)
                    elif 'Ø§Ù†Ù‡Ù‰ Ø§Ù„Ø®Ø·Ø©' in label:
                        stats['plan_completed'] = 'Ù†Ø¹Ù…' in value or 'yes' in value.lower()
        
            # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²
            if stats['total_hours_required'] > 0:
                completed = stats['total_hours_completed'] + stats['total_hours_transferred']
                stats['completion_percentage'] = round((completed / stats['total_hours_required']) * 100, 2)
            
        except Exception as e:
            logger.error(f"Error extracting stats: {e}")
        
        return stats
    
    def _extract_courses(self, soup) -> List[Dict[str, Any]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©"""
        courses = []
        
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª - ØªØ­Ø³ÙŠÙ† Ø§Ù†ØªÙ‚Ø§Ø¦ÙŠØ© Ø§Ù„Ø¹Ù†Ø§ØµØ±
            course_sections = soup.find_all('div', class_=lambda x: x and ('member-card' in x or 'panel' in x or 'card' in x))
            
            if not course_sections:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø© Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª
                course_tables = soup.find_all('table', class_='table')
                for table in course_tables:
                    # ØªØ®Ø·ÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
                    if table.find_previous_sibling('h4') or table.find_previous_sibling('h3'):
                        section_title = table.find_previous_sibling('h4') or table.find_previous_sibling('h3')
                        category = section_title.get_text(strip=True) if section_title else 'ØºÙŠØ± Ù…ØµÙ†Ù'
                        
                        rows = table.find_all('tr')[1:]  # ØªØ®Ø·ÙŠ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                        for row in rows:
                            cols = row.find_all('td')
                            if len(cols) >= 4:  # Ø¹Ø¯Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø£Ù‚Ù„ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ù‚Ø¨ÙˆÙ„Ø§Ù‹
                                course_data = self._parse_course_row(cols, category)
                                if course_data:
                                    courses.append(course_data)
                return courses
            
            for section in course_sections:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø³Ù…
                section_title = section.find('h4') or section.find('h3') or section.find('h2')
                category = section_title.get_text(strip=True) if section_title else 'ØºÙŠØ± Ù…ØµÙ†Ù'
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª
                table = section.find('table')
                if table:
                    rows = table.find_all('tr')[1:]  # ØªØ®Ø·ÙŠ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    
                    for row in rows:
                        cols = row.find_all('td')
                        if len(cols) >= 4:  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø£Ø¹Ù…Ø¯Ø©
                            course_data = self._parse_course_row(cols, category)
                            if course_data:
                                courses.append(course_data)
        
        except Exception as e:
            logger.error(f"Error extracting courses: {e}")
        
        return courses
    
    def _parse_course_row(self, cols, category) -> Optional[Dict[str, Any]]:
        """ØªØ­Ù„ÙŠÙ„ ØµÙ Ø§Ù„Ù…Ù‚Ø±Ø±"""
        try:
            # Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‚Ø±Ø± (Ù…Ù† Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø© Ø£Ùˆ Ø§Ù„Ù†Øµ)
            status = 'unknown'
            status_icon = cols[0].find('i')
            if status_icon:
                status_classes = status_icon.get('class', [])
                status = self._get_course_status(status_classes)
            else:
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø­Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ø£ÙŠÙ‚ÙˆÙ†Ø©
                status_text = cols[0].get_text(strip=True).lower()
                if 'Ù†Ø§Ø¬Ø­' in status_text or 'completed' in status_text:
                    status = 'completed'
                elif 'Ø±Ø§Ø³Ø¨' in status_text or 'failed' in status_text:
                    status = 'failed'
                elif 'Ù…Ø³Ø¬Ù„' in status_text or 'in progress' in status_text:
                    status = 'in_progress'
            
            # Ø±Ù…Ø² Ø§Ù„Ù…Ù‚Ø±Ø±
            course_code = cols[1].get_text(strip=True)
            course_code_elem = cols[1].find('a')
            if course_code_elem:
                course_code = course_code_elem.get_text(strip=True)
            
            # Ø§Ø³Ù… Ø§Ù„Ù…Ù‚Ø±Ø±
            course_name = cols[2].get_text(strip=True) if len(cols) > 2 else ''
            
            # Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª
            hours_text = cols[3].get_text(strip=True) if len(cols) > 3 else '0'
            hours = self._parse_number(hours_text)
            
            # Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©
            detailed_status = cols[4].get_text(strip=True) if len(cols) > 4 else ''
            
            return {
                'course_code': course_code,
                'course_name': course_name,
                'category': category,
                'hours': hours,
                'status': status,
                'detailed_status': detailed_status,
                'is_elective': 'Ø§Ø®ØªÙŠØ§Ø±ÙŠ' in category or 'elective' in category.lower()
            }
            
        except Exception as e:
            logger.error(f"Error parsing course row: {e}")
            return None
    
    
    # Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    async def update_student_data(chat_id: int) -> bool:
        """ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            user = get_user(chat_id)
            if not user or not user['student_id'] or not user['password']:
                logger.error(f"User data not found for chat_id: {chat_id}")
                return False
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø³ÙƒØ±Ø§Ø¨Ø±
            scraper = QOUScraper(user['student_id'], user['password'])
            
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
            if not scraper.login():
                logger.error(f"Login failed for student: {user['student_id']}")
                return False
            
            # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            study_plan_data = scraper.fetch_study_plan()
            
            if study_plan_data['status'] != 'success':
                logger.error(f"Failed to fetch study plan for student: {user['student_id']}")
                return False
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            save_student_stats(chat_id, study_plan_data['stats'])
            save_student_courses(chat_id, study_plan_data['courses'])
            
            logger.info(f"Successfully updated data for student: {user['student_id']}")
            return True
            
        except Exception as e:
            logger.error(f"Error updating student data for chat_id {chat_id}: {e}")
            return False
    
    def save_student_stats(chat_id: int, stats_data: Dict[str, Any]):
        """Ø­ÙØ¸ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©"""
        try:
            with get_conn() as conn:
                with conn.cursor() as cur:
                    cur.execute('''
                        INSERT INTO student_stats 
                        (chat_id, total_hours_required, total_hours_completed, 
                         total_hours_transferred, semesters_count, plan_completed, completion_percentage)
                        VALUES (%s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (chat_id) DO UPDATE SET
                            total_hours_required = EXCLUDED.total_hours_required,
                            total_hours_completed = EXCLUDED.total_hours_completed,
                            total_hours_transferred = EXCLUDED.total_hours_transferred,
                            semesters_count = EXCLUDED.semesters_count,
                            plan_completed = EXCLUDED.plan_completed,
                            completion_percentage = EXCLUDED.completion_percentage,
                            last_updated = CURRENT_TIMESTAMP
                    ''', (
                        chat_id,
                        stats_data.get('total_hours_required', 0),
                        stats_data.get('total_hours_completed', 0),
                        stats_data.get('total_hours_transferred', 0),
                        stats_data.get('semesters_count', 0),
                        stats_data.get('plan_completed', False),
                        stats_data.get('completion_percentage', 0)
                    ))
                conn.commit()
        except Exception as e:
            logger.error(f"Error saving student stats: {e}")
            # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø®Ø·Ø£ Ù‡Ù†Ø§
    
    def save_student_courses(chat_id: int, courses_data: List[Dict[str, Any]]):
        """Ø­ÙØ¸ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©"""
        try:
            with get_conn() as conn:
                with conn.cursor() as cur:
                    # Ø­Ø°Ù Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
                    cur.execute('DELETE FROM student_courses WHERE chat_id = %s', (chat_id,))
                    
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
                    for course in courses_data:
                        cur.execute('''
                            INSERT INTO student_courses 
                            (chat_id, course_code, course_name, category, hours, status, detailed_status, is_elective)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                        ''', (
                            chat_id,
                            course.get('course_code', ''),
                            course.get('course_name', ''),
                            course.get('category', ''),
                            course.get('hours', 0),
                            course.get('status', 'unknown'),
                            course.get('detailed_status', ''),
                            course.get('is_elective', False)
                        ))
                conn.commit()
        except Exception as e:
            logger.error(f"Error saving student courses: {e}")
            # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø®Ø·Ø£ Ù‡Ù†Ø§


